{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Colab\n","!pip install langchain openai\n","\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/work_space/Paper/NLP_2023')\n","with open('./Openai_API_Key.txt', 'r') as api:\n","    os.environ[\"OPENAI_API_KEY\"] = api.read()"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["## Local\n","import os\n","with open('./Openai_API_Key.txt', 'r') as api:\n","    os.environ[\"OPENAI_API_KEY\"] = api.read()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'module'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchain_model\u001b[39;00m \u001b[39mimport\u001b[39;00m sentiment_chain_model\n","File \u001b[1;32mg:\\내 드라이브\\work_space\\Paper\\NLP_2023\\util\\chain_model.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodule\u001b[39;00m \u001b[39mimport\u001b[39;00m sentiment_chat, positive_chat, negative_chat\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msentiment_chain_model\u001b[39m(text:\u001b[39mstr\u001b[39m, show_sentiment:\u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m      4\u001b[0m   user_chat \u001b[39m=\u001b[39m text\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'module'"]}],"source":["from util.chain_model import sentiment_chain_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ftaZh0xQhUL2"},"outputs":[],"source":["from langchain.chat_models import ChatOpenAI\n","from langchain.schema import HumanMessage, SystemMessage, AIMessage\n","from langchain.chains import create_tagging_chain, create_tagging_chain_pydantic\n","from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory\n","from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n","from langchain.chains import LLMChain\n","\n","def sentiment_chat(text:str):\n","  senti_chat = ChatOpenAI(model_name='gpt-4', temperature = 0)\n","  schema = {\n","      \"properties\": {\n","          \"sentiment\" : {\"type\" : \"string\", \"enum\" : ['Very Positive', 'Positive', 'Neutral', 'Negative', 'Verey Negative']},\n","          \"aggressiveness\": {\"type\" : 'integer', \"enum\" : [1,2,3,4,5], \"description\" : \"describes how aggressive the statement is, the higher the more aggressive\"}\n","      },\n","      \"required\" : [\"sentiment\", \"aggressiveness\"]\n","  }\n","  senti_chain = create_tagging_chain(schema, senti_chat)\n","  answer = senti_chain.run(text)\n","\n","  return answer\n","\n","def emotion_chat(text:str):\n","  emo_chat = ChatOpenAI(model_name='gpt-4', temperature = 0)\n","  schema = {\n","      \"properties\" : {\n","          \"emotion\" : {\"type\" : \"string\", \"enum\" : ['Anger', 'Disgust', 'Fear', 'Happiness', 'Contempt', 'Sadness', \"Surprise\"]},\n","          \"aggressiveness\": {\"type\" : 'integer', \"enum\" : [1,2,3,4,5], \"description\" : \"describes how aggressive the statement is, the higher the more aggressive\"}\n","      }\n","  }\n","  emo_chain = create_tagging_chain(schema, emo_chat)\n","  answer = emo_chain.run(text)\n","\n","  return answer\n","\n","\n","def positive_chat(text:str):\n","  positive_memory = ConversationBufferWindowMemory(k=1, memory_key=\"chat_history\", return_messages=True)\n","  positive_memory.save_context({\"input\" : \"믿고쓰는 상품! 너무나도 만족합니다. 항상 좋은 제품 제공해주셔서 너무나도 감사합니다. 배송도 빠르고 서비스도 너무 좋아요 ^^\"},\n","   {\"output\" : \"안녕하세요 고객님, 항상 저희 제품을 사용해주셔서 대단히 감사합니다. 앞으로도 좋은 서비스로 보답할 수 있도록 하겠습니다. 고맙습니다.\"})\n","\n","  llm = ChatOpenAI(model_name='gpt-4', temperature = 0.8)\n","  prompt = ChatPromptTemplate(messages = [\n","      SystemMessagePromptTemplate.from_template(\"당신은 긍정적인 리뷰에 답변을 달아주는 유용한 AI 봇입니다. 상대방의 칭찬에 감사와 고마움을 표하는 답변을 작성하세요.\"),\n","      MessagesPlaceholder(variable_name=\"chat_history\"),\n","      HumanMessagePromptTemplate.from_template(\"{question}\")\n","      ]\n","  )\n","\n","  conversation = LLMChain(\n","    llm=llm,\n","    prompt=prompt,\n","    verbose=False,\n","    memory=positive_memory\n","  )\n","\n","  answer = conversation({\"question\" : text})['text']\n","  return answer\n","\n","def negative_chat(text:str):\n","  negative_memory = ConversationBufferWindowMemory(k=1, memory_key=\"chat_history\", return_messages=True)\n","  negative_memory.save_context({\"input\" : \"예쁘고 심플해서 샀는데. 재질이 깔끄러워요. 살에 자국 다 베이고ㅠㅠ....폭망이에요. 재대로 확인안한 제 잘못이죠;;; 참고로 싱글세트 2. 퀸세트 1 샀습니다.\"},\n","   {\"output\" : \"안녕하세요 고객님, 먼저 저희 제품을 선택해 주신 것에 대한 감사함을 먼저 표합니다. 싱글세트와 퀸세트를 구매해주셨는데, 의도치않게 불편을 드리게 되어 정말로 죄송합니다. 추후에는 이러한 부분을 보완하여 더욱 좋은 상품을 제공할 수 있도록 노력하겠습니다. 감사합니다.\"})\n","\n","  llm = ChatOpenAI(model_name='gpt-4', temperature = 0.8)\n","  prompt = ChatPromptTemplate(messages = [\n","      SystemMessagePromptTemplate.from_template(\"당신은 부정적인 리뷰에 답변을 달아주는 유용한 AI 봇입니다. 고객의 마음을 이해하고 위로하는 답변을 작성하세요.\"),\n","      MessagesPlaceholder(variable_name=\"chat_history\"),\n","      HumanMessagePromptTemplate.from_template(\"{question}\")\n","      ]\n","  )\n","\n","  conversation = LLMChain(\n","    llm=llm,\n","    prompt=prompt,\n","    verbose=False,\n","    memory=negative_memory\n","  )\n","\n","  answer = conversation({\"question\" : text})['text']\n","  return answer\n","\n","def sentiment_chain_model(text:str, show_sentiment:bool=False):\n","  user_chat = text\n","  sentiment = sentiment_chat(user_chat)['sentiment']\n","\n","  if sentiment == ('Very Positive') or ('Positive'):\n","    asnwer = positive_chat(user_chat)\n","\n","  else:\n","    asnwer = negative_chat(user_chat)\n","\n","  if show_sentiment==True:\n","    return dict({'Sentiment' : sentiment, 'Asnwer' : asnwer})\n","  else:\n","    return asnwer\n"]},{"cell_type":"markdown","metadata":{"id":"VzQzd_YKoPO0"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1845,"status":"ok","timestamp":1691558997643,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"8W20hE-uxb4-","outputId":"ffbb269d-2e15-447e-9730-051563540e5a"},"outputs":[{"data":{"text/plain":["{'emotion': 'Happiness'}"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["emotion_chat('빠른 배송과 친절한 설명')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11131,"status":"ok","timestamp":1691559056261,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"k9jLQhoWptoI","outputId":"a287b65a-10d8-4bd0-a439-a329cac3e215"},"outputs":[{"data":{"text/plain":["{'Sentiment': 'Positive',\n"," 'Asnwer': '고객님, 빠른 배송과 친절한 서비스에 만족하셨다니 저희에게는 큰 힘이 됩니다. 고객님의 소중한 피드백 감사드립니다. 앞으로도 항상 최선을 다하겠습니다.'}"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["sentiment_chain_model('빠른 배송과 친절한 설명', show_sentiment=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":6495,"status":"ok","timestamp":1691556512267,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"LK2nfHs-mlbI","outputId":"29ec82b1-9d91-4731-a27d-a1d92ce1d88e"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'안녕하세요 고객님, 저희의 빠른 배송과 친절한 설명에 만족하셨다니 기쁩니다. 앞으로도 고객님께 더욱 좋은 서비스를 제공하도록 노력하겠습니다. 감사합니다.'"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["positive_chat('빠른 배송과 친절한 설명')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m7jPhZyN9gNA"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
